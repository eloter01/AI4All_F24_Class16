{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv into pandas dataframe\n",
    "\n",
    "#df = pd.read_csv(\"/Users/brisaniashley/Documents/School/AI4ALL Fall '24/AI4All_F24_Class16/big_startup_secsees_dataset.csv\")\n",
    "df = pd.read_csv(\"big_startup_secsees_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read saved filtered dataframe\n",
    "df2 = pd.read_csv(\"filtered_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dimensions of df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some sample records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some sample records\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['founded_at'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['first_funding_at'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique value of funding_rounds  \n",
    "df['funding_rounds'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data types of columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['founded_at'] = pd.to_datetime(df['founded_at']) #bad date\n",
    "#df['first_funding_at'] = pd.to_datetime(df['first_funding_at']) #bad date\n",
    "\n",
    "df['last_funding_at'] = pd.to_datetime(df['last_funding_at']) #successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find distribution of fundtin_total_usd column\n",
    "df['funding_total_usd'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_countries = pd.DataFrame(df.groupby('country_code').size())\n",
    "df_by_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_countries.loc['USA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO: \n",
    "\n",
    "- look into possible bias due to overrepresented data (in USA, for example)\n",
    "- Delete: 37176\t/organization/mousera\tMousera\n",
    "- Delete: 22208\t/organization/gamewheel\tGamewheel\thttp://gamewheel.co\n",
    "- Delete: harvard & trinity college (dublin)\n",
    "- Update: 7409\t/organization/blaze-bioscience\tBlaze Bioscience\thttp://www.blazebioscience.com, first round 2013-06-26 last round 2019-02-01, 6 funding rounds\n",
    "- Updated: 4776\t/organization/atipica\tAtipica\thttp://www.atipica.co, founded_at 2015-01-30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values, either:\n",
    "- drop rows\n",
    "- drop columns\n",
    "- fill in missing values with an appropriate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check columns for missing values in percentage\n",
    "df.isnull().mean() * 100\n",
    "# closest to zero is best, means 100% of data is filled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset (by number of missing values)\n",
    "missing_info = df.isnull().sum()\n",
    "print(missing_info[missing_info > 0])   # print columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns with Missing Data In Order of Concern: (NEED HELP TO CHECK OVER IF I AM CORRECT -ANTHONY)\n",
    "# name : Unchecked\n",
    "# homepage_url : Unchecked\n",
    "# category_list : unchecked \n",
    "# Country_Code : Unchecked \n",
    "# region: unchecked \n",
    "# city:unchecked \n",
    "# founded_at: unchecked\n",
    "# first_funding_at : unchecked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "          #Name\n",
    "#------------------------------#\n",
    "\n",
    "#find the index of the row with missing name\n",
    "# single_name_row = df[df['name'].isnull()]\n",
    "# print(single_name_row)\n",
    "\n",
    "#drop the row with missing name\n",
    "df.dropna(subset=['name'], inplace=True)\n",
    "\n",
    "#check if the row was dropped\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #Homepage URL\n",
    "#-----------------------------------#\n",
    "\n",
    "# fill missing values in homepage_url with 'No URL'\n",
    "df['homepage_url'].fillna('No URL', inplace=True) # fill missing 'homepage_url\" values with 'No URL'\n",
    "\n",
    "df.isnull().sum() # check if missing values are filled\n",
    "# df.head()\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "# df.to_csv('filtered_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #Category List\n",
    "#-----------------------------------#\n",
    "\n",
    "\n",
    "# # fill missing values in homepage_url with 'No URL'\n",
    "# df['category_list'].fillna('N/a', inplace=True)\n",
    "\n",
    "#or just drop the column \n",
    "# df.dropna(subset=['category_list'], inplace=True)\n",
    "\n",
    "#filters out rows with missing values in category_list\n",
    "df['category_list'].replace('N/a', pd.NA, inplace=True)\n",
    "df.dropna(subset=['category_list'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df.tail()\n",
    "df.head()\n",
    "\n",
    "\n",
    "df.isnull().sum() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #Country_Code\n",
    "#-----------------------------------#\n",
    "\n",
    "import pandas as pd\n",
    "# read csv into pandas dataframe\n",
    "\n",
    "\n",
    "# fill missing values in country_code with 'N/a'\n",
    "#df['country_code'].fillna('N/a', inplace=True)\n",
    "\n",
    "#or just drop the column\n",
    "# df.dropna(subset=['country_code'], inplace=True)\n",
    "\n",
    "#filters out rows with missing values in country_code\n",
    "df.dropna(subset=['country_code'], inplace=True)\n",
    "\n",
    "df.isnull().sum() \n",
    "df.tail()\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "# df.to_csv('filtered_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            #State_Code\n",
    "#-----------------------------------#\n",
    "\n",
    "# Load your data into a DataFrame\n",
    "df = pd.read_csv('big_startup_secsees_dataset.csv')  # Replace 'your_file.csv' with the path to your actual CSV file\n",
    "\n",
    "# Filter out rows where the 'State_Code' column is not a string\n",
    "df = df[df['state_code'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Display the number of missing values in each column to verify\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "# df.to_csv('filtered_df.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #City\n",
    "#-----------------------------------#\n",
    "\n",
    "#drop the column city, i dont think it relevant as we pretty much just need the states\n",
    "df.drop(columns=['city'], inplace=True)\n",
    "df.tail()\n",
    "\n",
    "# # Save the modified DataFrame back to a CSV file\n",
    "# df.to_csv('filtered_df.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            #Found_at\n",
    "#-----------------------------------#\n",
    "\n",
    "#filters out rows with missing values in founded_at\n",
    "df.dropna(subset=['founded_at'], inplace=True)\n",
    "\n",
    "df.isnull().sum() \n",
    "df.tail()\n",
    "\n",
    "# # Save the modified DataFrame back to a CSV file\n",
    "# df.to_csv('filtered_df.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            #First_funding_at \n",
    "#-----------------------------------#\n",
    "\n",
    "df.dropna(subset=['first_funding_at'], inplace=True)\n",
    "\n",
    "df.isnull().sum() \n",
    "# df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type of funding_total_usd to numerical\n",
    "df['funding_total_usd'] = pd.to_numeric(df['funding_total_usd'], errors='coerce')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Elminating OutLiers\n",
    "\n",
    "funding_total_usd    object\n",
    "funding_rounds        int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\$'\n",
      "C:\\Users\\heyok\\AppData\\Local\\Temp\\ipykernel_19728\\1829467177.py:2: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df['funding_total_usd'] = df['funding_total_usd'].replace(['[\\$,]', '-'], ['', 'NaN'], regex=True).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permalink               0\n",
      "name                    1\n",
      "homepage_url         2149\n",
      "category_list         451\n",
      "funding_total_usd       0\n",
      "status                  0\n",
      "country_code            0\n",
      "state_code              0\n",
      "region                221\n",
      "city                  219\n",
      "funding_rounds          0\n",
      "founded_at           7967\n",
      "first_funding_at       17\n",
      "last_funding_at         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check this over, i used chaptgpt for this one. Was lost \n",
    "\n",
    "\n",
    "# Convert 'funding_total_usd' to a numerical type (remove any non-numeric characters first)\n",
    "df['funding_total_usd'] = df['funding_total_usd'].replace(['[\\$,]', '-'], ['', 'NaN'], regex=True).astype(float)\n",
    "\n",
    "# Define a function to remove outliers using the IQR method\n",
    "def remove_outliers(df, column_name):\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
    "\n",
    "# Remove outliers from the specified numerical columns\n",
    "df_cleaned = remove_outliers(df, 'funding_total_usd')\n",
    "df_cleaned = remove_outliers(df_cleaned, 'funding_rounds')\n",
    "\n",
    "# Save the cleaned DataFrame back to a CSV file\n",
    "df_cleaned.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "# Display the number of missing values in each column to verify\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with Missing Data In Order of Concern:\n",
    "\n",
    "1. founded_at: 22.934245%\n",
    "2. state_code: 12.878194%\n",
    "3. region: 12.099204%\n",
    "4. city: 12.096191% \n",
    "5. country_code: 10.483968%\n",
    "6. homepage_url: 7.621143%\n",
    "7. category_list: 4.743250%\n",
    "8. first_funding_at: 0.036162%\n",
    "9. name: 0.001507%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permalink            object\n",
       "name                 object\n",
       "homepage_url         object\n",
       "category_list        object\n",
       "funding_total_usd    object\n",
       "status               object\n",
       "country_code         object\n",
       "state_code           object\n",
       "region               object\n",
       "funding_rounds        int64\n",
       "founded_at           object\n",
       "first_funding_at     object\n",
       "last_funding_at      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"big_startup_secsees_dataset.csv\")\n",
    "df.dtypes\n",
    "\n",
    "df2 = pd.read_csv(\"filtered_df.csv\")\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate new column to find average funding per funding round\n",
    "df['avg_funding_per_round'] = df['funding_total_usd'] / df['funding_rounds']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.region.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
